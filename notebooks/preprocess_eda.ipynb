{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6773fc1d",
   "metadata": {},
   "source": [
    "# Understanding the Model and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637125b6",
   "metadata": {},
   "source": [
    "## 2.1 Time Series Properties Analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf66674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('BrentOilPrices.csv', parse_dates=['Date'])\n",
    "df = df.sort_values('Date')\n",
    "\n",
    "# 1. Trend Analysis\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(df['Date'], df['Price'])\n",
    "plt.title('Brent Oil Price Trend (1987-2022)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Rolling statistics\n",
    "df['30_day_avg'] = df['Price'].rolling(window=30).mean()\n",
    "df['30_day_std'] = df['Price'].rolling(window=30).std()\n",
    "\n",
    "# 2. Stationarity Testing\n",
    "def test_stationarity(timeseries):\n",
    "    # Perform Dickey-Fuller test\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], \n",
    "                        index=['Test Statistic', 'p-value', '#Lags Used', 'Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput[f'Critical Value ({key})'] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "    # Determine stationarity\n",
    "    if dftest[1] <= 0.05:\n",
    "        print(\"Data is stationary\")\n",
    "    else:\n",
    "        print(\"Data is non-stationary\")\n",
    "\n",
    "print(\"Testing stationarity of raw prices:\")\n",
    "test_stationarity(df['Price'])\n",
    "\n",
    "# 3. Log returns for stationarity\n",
    "df['Log_Return'] = np.log(df['Price']) - np.log(df['Price'].shift(1))\n",
    "\n",
    "print(\"\\nTesting stationarity of log returns:\")\n",
    "test_stationarity(df['Log_Return'].dropna())\n",
    "\n",
    "# 4. Volatility Patterns\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(df['Date'], df['Log_Return'])\n",
    "plt.title('Log Returns - Volatility Clustering')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Log Return')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "df['Log_Return'].rolling(window=30).std().plot()\n",
    "plt.title('30-Day Rolling Volatility')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Volatility')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200edf90",
   "metadata": {},
   "source": [
    "## Build Bayesian Change Point Model (PyMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dbbc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "price_data = df['Price'].values\n",
    "n = len(price_data)\n",
    "\n",
    "with pm.Model() as model:\n",
    "    # Prior for change point (tau)\n",
    "    tau = pm.DiscreteUniform(\"tau\", lower=0, upper=n-1)\n",
    "    \n",
    "    # Means before and after change point\n",
    "    mu1 = pm.Normal(\"mu1\", mu=price_data.mean(), sigma=10)\n",
    "    mu2 = pm.Normal(\"mu2\", mu=price_data.mean(), sigma=10)\n",
    "    \n",
    "    # Switch function\n",
    "    mean = pm.math.switch(tau > np.arange(n), mu1, mu2)\n",
    "    \n",
    "    # Likelihood\n",
    "    likelihood = pm.Normal(\"likelihood\", mu=mean, sigma=1, observed=price_data)\n",
    "    \n",
    "    # Sampling\n",
    "    trace = pm.sample(2000, tune=1000, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8051cf4c",
   "metadata": {},
   "source": [
    "## Interpret Model Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check convergence\n",
    "az.summary(trace)\n",
    "\n",
    "# Plot trace\n",
    "az.plot_trace(trace)\n",
    "\n",
    "# Plot posterior of tau\n",
    "az.plot_posterior(trace, var_names=[\"tau\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7055c6",
   "metadata": {},
   "source": [
    "Modeling Implications:\n",
    "\n",
    "Non-stationarity in prices → Need differencing or log returns\n",
    "\n",
    "Volatility clustering → Consider GARCH models for advanced analysis\n",
    "\n",
    "Multiple regimes → Markov-switching models could be beneficial\n",
    "\n",
    "2.2 Change Point Models Explanation:\n",
    "Purpose in Context:\n",
    "Change point models identify structural breaks where statistical properties of a time series change abruptly. For Brent oil prices:\n",
    "\n",
    "Detect regime shifts between high/low volatility periods\n",
    "\n",
    "Identify dates when mean price level changes significantly\n",
    "\n",
    "Separate calm periods from crisis periods\n",
    "\n",
    "How They Help:\n",
    "\n",
    "Objective Identification: Data-driven detection vs. subjective event selection\n",
    "\n",
    "Quantification: Measure magnitude of change (mean shift, variance change)\n",
    "\n",
    "Timing Precision: Identify exact dates of structural breaks\n",
    "\n",
    "Causal Inference Support: Provide evidence for event impact hypotheses\n",
    "\n",
    "2.3 Expected Outputs and Limitations:\n",
    "Expected Outputs:\n",
    "\n",
    "Change Point Dates: Posterior distribution of τ (change point location)\n",
    "\n",
    "Parameter Estimates: Distributions for μ₁ (mean before) and μ₂ (mean after)\n",
    "\n",
    "Impact Quantification: Probability distribution of price change magnitude\n",
    "\n",
    "Uncertainty Measures: Credible intervals for all estimates\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Assumes at most one change point in the analyzed period\n",
    "\n",
    "Sensitive to prior distributions\n",
    "\n",
    "Requires careful convergence diagnostics\n",
    "\n",
    "May miss gradual transitions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
